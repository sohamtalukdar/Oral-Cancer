{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # install dependencies:\n",
    "# ! pip install --upgrade optuna\n",
    "# ! pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1\n",
    "# ! pip install cython pyyaml==5.1\n",
    "# ! pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "# import torch, torchvision\n",
    "# print(torch.__version__, torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "import wandb\n",
    "from detectron2.config import get_cfg\n",
    "import optuna\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def cv2_imshow(img):\n",
    "    \"\"\"Display an image using matplotlib.\"\"\"\n",
    "    # Convert BGR image to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.axis('off')  # Hide the axis values\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### improve the image using preprocessing\n",
    "import os\n",
    "\n",
    "# Define the image enhancement function\n",
    "def enhance_image(input_path, output_path):\n",
    "    # Load the image\n",
    "    img = cv2.imread(input_path, cv2.IMREAD_COLOR)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB\n",
    "\n",
    "    # 1. Noise Removal using Median Filter\n",
    "    denoised_img = cv2.medianBlur(img_rgb, 5)\n",
    "\n",
    "    # 2. Enhance Contrast using CLAHE\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    denoised_img_gray = cv2.cvtColor(denoised_img, cv2.COLOR_RGB2GRAY)  # Convert to grayscale for CLAHE\n",
    "    contrast_enhanced_img_gray = clahe.apply(denoised_img_gray)\n",
    "    contrast_enhanced_img = cv2.cvtColor(contrast_enhanced_img_gray, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    # 3. Sharpening using Unsharp Mask\n",
    "    blurred = cv2.GaussianBlur(contrast_enhanced_img, (5,5), 0)\n",
    "    sharpened = cv2.addWeighted(contrast_enhanced_img, 1.5, blurred, -0.5, 0)\n",
    "    \n",
    "    # Save the enhanced image\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(sharpened, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "# Main code to apply enhancement to each directory\n",
    "directories = [\"train\", \"test\", \"valid\"]\n",
    "for directory in directories:\n",
    "    input_dir = f\"/home/soham/oral_cancer/detectron2/combined_set/{directory}/images\"  # Input directory (change this to your actual path)\n",
    "    output_dir = f\"/home/soham/oral_cancer/detectron2/enhanced_set/enhanced_{directory}\"  # Output directory (change this if needed)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Loop through each image in the directory\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".jpg\"):  # Check for JPEG images (you can add more formats if needed)\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "            enhance_image(input_path, output_path)\n",
    "\n",
    "# Note: This code will not run here as I don't have access to the directories.\n",
    "# You can run this code on your machine after setting the correct paths.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\"my_dataset_train\", {}, \"/home/soham/oral_cancer/detectron2/combined_set/train/output_coco_format_train.json\", \"/home/soham/oral_cancer/detectron2/enhanced_set/enhanced_train/\")\n",
    "register_coco_instances(\"my_dataset_val\", {}, \"/home/soham/oral_cancer/detectron2/combined_set/valid/output_coco_format_valid.json\", \"/home/soham/oral_cancer/detectron2/enhanced_set/enhanced_valid/\")\n",
    "register_coco_instances(\"my_dataset_test\", {}, \"/home/soham/oral_cancer/detectron2/combined_set/test/output_coco_format_test.json\", \"/home/soham/oral_cancer/detectron2/enhanced_set/enhanced_test/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize training data\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "\n",
    "import random\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "for d in random.sample(dataset_dicts, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=my_dataset_train_metadata, scale=0.5)\n",
    "    vis = visualizer.draw_dataset_dict(d)\n",
    "    cv2_imshow(vis.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We are importing our own Trainer Module here to use the COCO validation evaluation during training. Otherwise no validation eval occurs.\n",
    "\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "\n",
    "class CocoTrainer(DefaultTrainer):\n",
    "\n",
    "  @classmethod\n",
    "  def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "\n",
    "    if output_folder is None:\n",
    "        os.makedirs(\"coco_eval\", exist_ok=True)\n",
    "        output_folder = \"coco_eval\"\n",
    "\n",
    "    return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "#from detectron2.evaluation.coco_evaluation import COCOEvaluator\n",
    "import os\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "\n",
    "cfg.DATALOADER.NUM_WORKERS = 4\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "\n",
    "cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "cfg.SOLVER.MAX_ITER = 1500 #adjust up if val mAP is still rising, adjust down if overfit\n",
    "cfg.SOLVER.STEPS = (1000, 1500)\n",
    "cfg.SOLVER.GAMMA = 0.05\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4 #your number of classes + 1\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = CocoTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import optuna\n",
    "# import wandb\n",
    "# from optuna.integration import WandbCallback\n",
    "\n",
    "# def objective(trial):\n",
    "#     # Start a new wandb run for each trial\n",
    "#     wandb.init(project=\"detectron2_training_oralcancer\", name=f\"run-{trial.number}\", sync_tensorboard=True)\n",
    "    \n",
    "#     cfg = get_cfg()\n",
    "#     cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "#     cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "#     cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "#     cfg.DATALOADER.NUM_WORKERS = 4\n",
    "#     cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "    \n",
    "#     # Hyperparameters to optimize\n",
    "#     cfg.SOLVER.IMS_PER_BATCH = trial.suggest_int(\"IMS_PER_BATCH\", 2, 8, 16, 32, 64)\n",
    "#     cfg.SOLVER.BASE_LR = trial.suggest_float(\"BASE_LR\", 1e-5, 1e-1, log=True)\n",
    "#     cfg.SOLVER.WARMUP_ITERS = trial.suggest_int(\"WARMUP_ITERS\", 500, 2000)\n",
    "#     cfg.SOLVER.MAX_ITER = trial.suggest_int(\"MAX_ITER\", 1000, 2000, 3000)\n",
    "#     cfg.SOLVER.STEPS = (trial.suggest_int(\"STEPS_1\", 500, 1000, 1500, 2000),)\n",
    "#     cfg.SOLVER.GAMMA = trial.suggest_float(\"GAMMA\", 0.01, 0.1)\n",
    "#     cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = trial.suggest_int(\"BATCH_SIZE_PER_IMAGE\", 32, 128)\n",
    "#     cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "#     cfg.TEST.EVAL_PERIOD = 500\n",
    "    \n",
    "#     # Log the config to wandb\n",
    "#     wandb.config.update({k: v for k, v in cfg.items()})\n",
    "\n",
    "#     os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#     trainer = CocoTrainer(cfg)\n",
    "#     trainer.resume_or_load(resume=False)\n",
    "#     trainer.train()\n",
    "\n",
    "#     # Assuming the trainer returns validation loss; if not, replace this with your validation metric\n",
    "#     val_loss = trainer.validate()\n",
    "\n",
    "#     wandb.log({\"validation_loss\": val_loss})\n",
    "    \n",
    "#     # End the wandb run for this trial\n",
    "#     wandb.finish()\n",
    "\n",
    "#     # Return the validation loss\n",
    "#     return val_loss\n",
    "\n",
    "# # Create a study and optimize the objective\n",
    "# study = optuna.create_study(direction=\"minimize\")\n",
    "# study.optimize(objective, n_trials=30, callbacks=[WandbCallback()])  # Adjust n_trials based on your preference\n",
    "\n",
    "# print(f\"Best trial: {study.best_trial.params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"detectron2_training_oralcancer\", name = \"run-1\" ,sync_tensorboard=True)\n",
    "\n",
    "# cfg = get_cfg()\n",
    "# cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\"))\n",
    "# cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
    "# cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "# cfg.DATALOADER.NUM_WORKERS = 4\n",
    "# cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml\")\n",
    "# cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "# cfg.SOLVER.BASE_LR = 0.001\n",
    "# cfg.SOLVER.WARMUP_ITERS = 1000\n",
    "# cfg.SOLVER.MAX_ITER = 1500\n",
    "# cfg.SOLVER.STEPS = (1000,)\n",
    "# cfg.SOLVER.GAMMA = 0.05\n",
    "# cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n",
    "# cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2\n",
    "# cfg.TEST.EVAL_PERIOD = 500  \n",
    "\n",
    "# # Log the config to wandb\n",
    "# wandb.config.update({k: v for k, v in cfg.items()})\n",
    "\n",
    "# os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "# trainer = CocoTrainer(cfg)\n",
    "# trainer.resume_or_load(resume=False)\n",
    "# trainer.train()\n",
    "\n",
    "# # End the wandb run after training\n",
    "# wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # test evaluation\n",
    "    from detectron2.data import DatasetCatalog, MetadataCatalog, build_detection_test_loader\n",
    "    from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "    wandb.init(project='detectron2_training_oralcancer', name = \"run-1\",  resume=True)\n",
    "\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.85\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    evaluator = COCOEvaluator(\"my_dataset_test\", cfg, False, output_dir=\"./output/\")\n",
    "    val_loader = build_detection_test_loader(cfg, \"my_dataset_test\")\n",
    "    results = inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "\n",
    "    # Log evaluation metrics to wandb\n",
    "    wandb.log(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.DATASETS.TEST = (\"my_dataset_test\", )\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)\n",
    "test_metadata = MetadataCatalog.get(\"my_dataset_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you've already initialized `predictor` and `test_metadata` somewhere\n",
    "\n",
    "for imageName in glob.glob('/content/test/*jpg'):\n",
    "    im = cv2.imread(imageName)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=test_metadata,\n",
    "                   scale=0.8)\n",
    "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    \n",
    "    # Use matplotlib to display the image\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
