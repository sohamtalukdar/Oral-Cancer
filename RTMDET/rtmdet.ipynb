{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "HOME = os.getcwd()\n",
    "print(\"HOME:\", HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git clone https://github.com/open-mmlab/mmyolo.git\n",
    "\n",
    "# ! cd $HOME/mmyolo && pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import random\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.apis import init_detector, inference_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p {HOME}/weights\n",
    "# ! wget -P {HOME}/weights -q https://download.openmmlab.com/mmyolo/v0/rtmdet/rtmdet_s_syncbn_fast_8xb32-300e_coco/rtmdet_s_syncbn_fast_8xb32-300e_coco_20221230_182329-0a8c901a.pth\n",
    "# ! ls -lh {HOME}/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! mkdir -p {HOME}/data\n",
    "# ! aws s3 sync s3://oralcancer/combined_set/ $HOME/data/\n",
    "# ! ls -lh {HOME}/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "CONFIG_PATH = f\"{HOME}/mmyolo/configs/rtmdet/rtmdet_l_syncbn_fast_8xb32-300e_coco.py\"\n",
    "WEIGHTS_PATH = f\"{HOME}/weights/rtmdet_l_syncbn_fast_8xb32-300e_coco_20230102_135928-ee3abdc4.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_detector(CONFIG_PATH, WEIGHTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "MAX_EPOCHS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_CONFIG_PATH = f\"{HOME}/mmyolo/configs/rtmdet/custom.py\"\n",
    "\n",
    "CUSTOM_CONFIG = f\"\"\"\n",
    "_base_ = ['../_base_/default_runtime.py', '../_base_/det_p5_tta.py']\n",
    "\n",
    "# ========================Frequently modified parameters======================\n",
    "# -----data related-----\n",
    "data_root = '/home/soham/Oral-Cancer/RTMDET/data/'\n",
    "\n",
    "train_ann_file = 'train/output_coco_format_train_updated.json'\n",
    "train_data_prefix = 'train/images/'\n",
    "\n",
    "val_ann_file = 'valid/output_coco_format_valid_updated.json'\n",
    "val_data_prefix = 'valid/images/'\n",
    "\n",
    "class_name = ('malignant', 'benign')\n",
    "num_classes = 2\n",
    "\n",
    "metainfo = dict(classes=class_name, palette=[(20, 220, 60)])\n",
    "\n",
    "train_batch_size_per_gpu = {BATCH_SIZE}\n",
    "# Worker to pre-fetch data for each single GPU during training\n",
    "train_num_workers = 4\n",
    "# persistent_workers must be False if num_workers is 0.\n",
    "persistent_workers = True\n",
    "\n",
    "# -----train val related-----\n",
    "# Base learning rate for optim_wrapper. Corresponding to 8xb16=64 bs\n",
    "base_lr = 0.004\n",
    "max_epochs = {MAX_EPOCHS}  # Maximum training epochs\n",
    "# Change train_pipeline for final 20 epochs (stage 2)\n",
    "num_epochs_stage2 = 20\n",
    "\n",
    "model_test_cfg = dict(\n",
    "    # The config of multi-label for multi-class prediction.\n",
    "    multi_label=True,\n",
    "    # The number of boxes before NMS\n",
    "    nms_pre=30000,\n",
    "    score_thr=0.001,  # Threshold to filter out boxes.\n",
    "    nms=dict(type='nms', iou_threshold=0.65),  # NMS type and threshold\n",
    "    max_per_img=300)  # Max number of detections of each image\n",
    "\n",
    "# ========================Possible modified parameters========================\n",
    "# -----data related-----\n",
    "img_scale = (640, 640)  # width, height\n",
    "# ratio range for random resize\n",
    "random_resize_ratio_range = (0.1, 2.0)\n",
    "# Cached images number in mosaic\n",
    "mosaic_max_cached_images = 40\n",
    "# Number of cached images in mixup\n",
    "mixup_max_cached_images = 20\n",
    "# Dataset type, this will be used to define the dataset\n",
    "dataset_type = 'YOLOv5CocoDataset'\n",
    "# Batch size of a single GPU during validation\n",
    "val_batch_size_per_gpu = 32\n",
    "# Worker to pre-fetch data for each single GPU during validation\n",
    "val_num_workers = 10\n",
    "\n",
    "# Config of batch shapes. Only on val.\n",
    "batch_shapes_cfg = dict(\n",
    "    type='BatchShapePolicy',\n",
    "    batch_size=val_batch_size_per_gpu,\n",
    "    img_size=img_scale[0],\n",
    "    size_divisor=32,\n",
    "    extra_pad_ratio=0.5)\n",
    "\n",
    "# -----model related-----\n",
    "# The scaling factor that controls the depth of the network structure\n",
    "deepen_factor = 1.0\n",
    "# The scaling factor that controls the width of the network structure\n",
    "widen_factor = 1.0\n",
    "# Strides of multi-scale prior box\n",
    "strides = [8, 16, 32]\n",
    "\n",
    "norm_cfg = dict(type='BN')  # Normalization config\n",
    "\n",
    "# -----train val related-----\n",
    "lr_start_factor = 1.0e-5\n",
    "dsl_topk = 13  # Number of bbox selected in each level\n",
    "loss_cls_weight = 1.0\n",
    "loss_bbox_weight = 2.0\n",
    "qfl_beta = 2.0  # beta of QualityFocalLoss\n",
    "weight_decay = 0.05\n",
    "\n",
    "# Save model checkpoint and validation intervals\n",
    "save_checkpoint_intervals = 10\n",
    "# validation intervals in stage 2\n",
    "val_interval_stage2 = 1\n",
    "# The maximum checkpoints to keep.\n",
    "max_keep_ckpts = 3\n",
    "# single-scale training is recommended to\n",
    "# be turned on, which can speed up training.\n",
    "env_cfg = dict(cudnn_benchmark=True)\n",
    "\n",
    "# ===============================Unmodified in most cases====================\n",
    "# https://mmengine.readthedocs.io/en/latest/api/visualization.html\n",
    "_base_.visualizer.vis_backends = [\n",
    "    dict(type='LocalVisBackend'), #\n",
    "    dict(type='TensorboardVisBackend'),]\n",
    "\n",
    "model = dict(\n",
    "    type='YOLODetector',\n",
    "    data_preprocessor=dict(\n",
    "        type='YOLOv5DetDataPreprocessor',\n",
    "        mean=[103.53, 116.28, 123.675],\n",
    "        std=[57.375, 57.12, 58.395],\n",
    "        bgr_to_rgb=False),\n",
    "    backbone=dict(\n",
    "        type='CSPNeXt',\n",
    "        arch='P5',\n",
    "        expand_ratio=0.5,\n",
    "        deepen_factor=deepen_factor,\n",
    "        widen_factor=widen_factor,\n",
    "        channel_attention=True,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='SiLU', inplace=True)),\n",
    "    neck=dict(\n",
    "        type='CSPNeXtPAFPN',\n",
    "        deepen_factor=deepen_factor,\n",
    "        widen_factor=widen_factor,\n",
    "        in_channels=[256, 512, 1024],\n",
    "        out_channels=256,\n",
    "        num_csp_blocks=3,\n",
    "        expand_ratio=0.5,\n",
    "        norm_cfg=norm_cfg,\n",
    "        act_cfg=dict(type='SiLU', inplace=True)),\n",
    "    bbox_head=dict(\n",
    "        type='RTMDetHead',\n",
    "        head_module=dict(\n",
    "            type='RTMDetSepBNHeadModule',\n",
    "            num_classes=num_classes,\n",
    "            in_channels=256,\n",
    "            stacked_convs=2,\n",
    "            feat_channels=256,\n",
    "            norm_cfg=norm_cfg,\n",
    "            act_cfg=dict(type='SiLU', inplace=True),\n",
    "            share_conv=True,\n",
    "            pred_kernel_size=1,\n",
    "            featmap_strides=strides),\n",
    "        prior_generator=dict(\n",
    "            type='mmdet.MlvlPointGenerator', offset=0, strides=strides),\n",
    "        bbox_coder=dict(type='DistancePointBBoxCoder'),\n",
    "        loss_cls=dict(\n",
    "            type='mmdet.QualityFocalLoss',\n",
    "            use_sigmoid=True,\n",
    "            beta=qfl_beta,\n",
    "            loss_weight=loss_cls_weight),\n",
    "        loss_bbox=dict(type='mmdet.GIoULoss', loss_weight=loss_bbox_weight)),\n",
    "    train_cfg=dict(\n",
    "        assigner=dict(\n",
    "            type='BatchDynamicSoftLabelAssigner',\n",
    "            num_classes=num_classes,\n",
    "            topk=dsl_topk,\n",
    "            iou_calculator=dict(type='mmdet.BboxOverlaps2D')),\n",
    "        allowed_border=-1,\n",
    "        pos_weight=-1,\n",
    "        debug=False),\n",
    "    test_cfg=model_test_cfg,\n",
    ")\n",
    "\n",
    "train_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=_base_.backend_args),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='Mosaic',\n",
    "        img_scale=img_scale,\n",
    "        use_cached=True,\n",
    "        max_cached_images=mosaic_max_cached_images,\n",
    "        pad_val=114.0),\n",
    "    dict(\n",
    "        type='mmdet.RandomResize',\n",
    "        # img_scale is (width, height)\n",
    "        scale=(img_scale[0] * 2, img_scale[1] * 2),\n",
    "        ratio_range=random_resize_ratio_range,\n",
    "        resize_type='mmdet.Resize',\n",
    "        keep_ratio=True),\n",
    "    dict(type='mmdet.RandomCrop', crop_size=img_scale),\n",
    "    dict(type='mmdet.YOLOXHSVRandomAug'),\n",
    "    dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "    dict(type='mmdet.Pad', size=img_scale, pad_val=dict(img=(114, 114, 114))),\n",
    "    dict(\n",
    "        type='YOLOv5MixUp',\n",
    "        use_cached=True,\n",
    "        max_cached_images=mixup_max_cached_images),\n",
    "    dict(type='mmdet.PackDetInputs')\n",
    "]\n",
    "\n",
    "train_pipeline_stage2 = [\n",
    "    dict(type='LoadImageFromFile', backend_args=_base_.backend_args),\n",
    "    dict(type='LoadAnnotations', with_bbox=True),\n",
    "    dict(\n",
    "        type='mmdet.RandomResize',\n",
    "        scale=img_scale,\n",
    "        ratio_range=random_resize_ratio_range,\n",
    "        resize_type='mmdet.Resize',\n",
    "        keep_ratio=True),\n",
    "    dict(type='mmdet.RandomCrop', crop_size=img_scale),\n",
    "    dict(type='mmdet.YOLOXHSVRandomAug'),\n",
    "    dict(type='mmdet.RandomFlip', prob=0.5),\n",
    "    dict(type='mmdet.Pad', size=img_scale, pad_val=dict(img=(114, 114, 114))),\n",
    "    dict(type='mmdet.PackDetInputs')\n",
    "]\n",
    "\n",
    "test_pipeline = [\n",
    "    dict(type='LoadImageFromFile', backend_args=_base_.backend_args),\n",
    "    dict(type='YOLOv5KeepRatioResize', scale=img_scale),\n",
    "    dict(\n",
    "        type='LetterResize',\n",
    "        scale=img_scale,\n",
    "        allow_scale_up=False,\n",
    "        pad_val=dict(img=114)),\n",
    "    dict(type='LoadAnnotations', with_bbox=True, _scope_='mmdet'),\n",
    "    dict(\n",
    "        type='mmdet.PackDetInputs',\n",
    "        meta_keys=('img_id', 'img_path', 'ori_shape', 'img_shape',\n",
    "                   'scale_factor', 'pad_param'))\n",
    "]\n",
    "\n",
    "train_dataloader = dict(\n",
    "    batch_size=train_batch_size_per_gpu,\n",
    "    num_workers=train_num_workers,\n",
    "    persistent_workers=persistent_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=dict(type='yolov5_collate'),\n",
    "    sampler=dict(type='DefaultSampler', shuffle=True),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        metainfo=metainfo,\n",
    "        ann_file=train_ann_file,\n",
    "        data_prefix=dict(img=train_data_prefix),\n",
    "        filter_cfg=dict(filter_empty_gt=True, min_size=32),\n",
    "        pipeline=train_pipeline))\n",
    "\n",
    "val_dataloader = dict(\n",
    "    batch_size=val_batch_size_per_gpu,\n",
    "    num_workers=val_num_workers,\n",
    "    persistent_workers=persistent_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False,\n",
    "    sampler=dict(type='DefaultSampler', shuffle=False),\n",
    "    dataset=dict(\n",
    "        type=dataset_type,\n",
    "        data_root=data_root,\n",
    "        metainfo=metainfo,\n",
    "        ann_file=val_ann_file,\n",
    "        data_prefix=dict(img=val_data_prefix),\n",
    "        test_mode=True,\n",
    "        batch_shapes_cfg=batch_shapes_cfg,\n",
    "        pipeline=test_pipeline))\n",
    "\n",
    "test_dataloader = val_dataloader\n",
    "\n",
    "# Reduce evaluation time\n",
    "val_evaluator = dict(\n",
    "    type='mmdet.CocoMetric',\n",
    "    proposal_nums=(100, 1, 10),\n",
    "    ann_file=data_root + val_ann_file,\n",
    "    metric='bbox')\n",
    "test_evaluator = val_evaluator\n",
    "\n",
    "# optimizer\n",
    "optim_wrapper = dict(\n",
    "    type='OptimWrapper',\n",
    "    optimizer=dict(type='AdamW', lr=base_lr, weight_decay=weight_decay),\n",
    "    paramwise_cfg=dict(\n",
    "        norm_decay_mult=0, bias_decay_mult=0, bypass_duplicate=True))\n",
    "\n",
    "# learning rate\n",
    "param_scheduler = [\n",
    "    dict(\n",
    "        type='LinearLR',\n",
    "        start_factor=lr_start_factor,\n",
    "        by_epoch=False,\n",
    "        begin=0,\n",
    "        end=1000),\n",
    "    dict(\n",
    "        # use cosine lr from 150 to 300 epoch\n",
    "        type='CosineAnnealingLR',\n",
    "        eta_min=base_lr * 0.05,\n",
    "        begin=max_epochs // 2,\n",
    "        end=max_epochs,\n",
    "        T_max=max_epochs // 2,\n",
    "        by_epoch=True,\n",
    "        convert_to_iter_based=True),\n",
    "]\n",
    "\n",
    "# hooks\n",
    "default_hooks = dict(\n",
    "    checkpoint=dict(\n",
    "        type='CheckpointHook',\n",
    "        interval=save_checkpoint_intervals,\n",
    "        max_keep_ckpts=max_keep_ckpts  # only keep latest 3 checkpoints\n",
    "    ))\n",
    "\n",
    "custom_hooks = [\n",
    "    dict(\n",
    "        type='EMAHook',\n",
    "        ema_type='ExpMomentumEMA',\n",
    "        momentum=0.0002,\n",
    "        update_buffers=True,\n",
    "        strict_load=False,\n",
    "        priority=49),\n",
    "    dict(\n",
    "        type='mmdet.PipelineSwitchHook',\n",
    "        switch_epoch=max_epochs - num_epochs_stage2,\n",
    "        switch_pipeline=train_pipeline_stage2)\n",
    "]\n",
    "\n",
    "train_cfg = dict(\n",
    "    type='EpochBasedTrainLoop',\n",
    "    max_epochs=max_epochs,\n",
    "    val_interval=save_checkpoint_intervals,\n",
    "    dynamic_intervals=[(max_epochs - num_epochs_stage2, val_interval_stage2)])\n",
    "\n",
    "val_cfg = dict(type='ValLoop')\n",
    "test_cfg = dict(type='TestLoop')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CUSTOM_CONFIG_PATH, 'w') as file:\n",
    "    file.write(CUSTOM_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd $HOME/mmyolo && python tools/train.py configs/rtmdet/custom.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ! pip install tensorboard\n",
    "# ! tensorboard --logdir /home/soham/Oral-Cancer/RTMDET/mmyolo/work_dirs/custom/20230914_121331\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_WEIGHTS_PATH = f\"/home/soham/Oral-Cancer/RTMDET/mmyolo/work_dirs/custom/epoch_{MAX_EPOCHS}.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_detector(CUSTOM_CONFIG_PATH, CUSTOM_WEIGHTS_PATH, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path= \"/home/soham/Oral-Cancer/RTMDET/data/test/images\",\n",
    "    annotations_path= \"/home/soham/Oral-Cancer/RTMDET/data/test/output_coco_format_test_updated.json\",\n",
    ")\n",
    "\n",
    "images = list(ds.images.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = random.choice(images)\n",
    "result = inference_detector(model, image)\n",
    "detections = sv.Detections.from_mmdetection(result)\n",
    "detections = detections[detections.confidence > 0.4].with_nms()\n",
    "\n",
    "box_annotator = sv.BoxAnnotator()\n",
    "labels = [\n",
    "    f\"{ds.classes[class_id]} {confidence:0.2f}\"\n",
    "    for _, _, confidence, class_id, _\n",
    "    in detections\n",
    "]\n",
    "annotated_image = box_annotator.annotate(image.copy(), detections, labels=labels)\n",
    "sv.plot_image(image=annotated_image, size=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.35\n",
    "NMS_IOU_THRESHOLD = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = sv.DetectionDataset.from_coco(\n",
    "    images_directory_path= \"/home/soham/Oral-Cancer/RTMDET/data/test/images\",\n",
    "    annotations_path= \"/home/soham/Oral-Cancer/RTMDET/data/test/output_coco_format_test_updated.json\",\n",
    ")\n",
    "\n",
    "print('dataset classes:', ds.classes)\n",
    "print('dataset size:', len(ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback(image: np.ndarray) -> sv.Detections:\n",
    "    result = inference_detector(model, image)\n",
    "    detections = sv.Detections.from_mmdetection(result)\n",
    "    return detections[detections.confidence > CONFIDENCE_THRESHOLD].with_nms(threshold=NMS_IOU_THRESHOLD)\n",
    "\n",
    "\n",
    "confusion_matrix = sv.ConfusionMatrix.benchmark(\n",
    "    dataset = ds,\n",
    "    callback = callback\n",
    ")\n",
    "\n",
    "_ = confusion_matrix.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_average_precision = sv.MeanAveragePrecision.benchmark(\n",
    "    dataset = ds,\n",
    "    callback = callback\n",
    ")\n",
    "\n",
    "print('mAP:', mean_average_precision.map50_95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_map = mean_average_precision.per_class_ap50_95.mean(axis=1)\n",
    "for class_name, value in zip(ds.classes, per_class_map):\n",
    "    print(f\"{class_name}: {value:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
